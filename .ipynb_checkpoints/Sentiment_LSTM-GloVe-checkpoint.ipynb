{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment classifier for tweets about GOT Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cata/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import bcolz\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, Input, LSTM \n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.regularizers import l2\n",
    "from keras.datasets import imdb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imdb film reviwes dataset can be directly imported in keras. It contains positive and negative reviews and is the most commen datset used for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_arr = sorted(idx, key=idx.get)\n",
    "idx_arr[:10]\n",
    "vocab = list(idx_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have contructed the vocabulary; now, since any model uses numbers, we need two dictionaries, one mapping each word to an index and the second, the inverse of this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_dict(d):\n",
    "    return dict([(v, k) for k, v in d.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v: k for k, v in idx.items()}\n",
    "word2idx = invert_dict(idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_file('imdb_full.pkl',\n",
    "                origin='https://s3.amazonaws.com/text-datasets/imdb_full.pkl',\n",
    "                md5_hash='d091312047c43cf9e4e38fef92437263')\n",
    "f = open(path, 'rb')\n",
    "(x_train, y_train), (x_test, y_test) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to predict on the dataset we have created with tweets about Game of Thrones characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>euron</th>\n",
       "      <th>sansa</th>\n",
       "      <th>jaime</th>\n",
       "      <th>arya</th>\n",
       "      <th>tyrion</th>\n",
       "      <th>bran</th>\n",
       "      <th>night</th>\n",
       "      <th>daenerys</th>\n",
       "      <th>cersei</th>\n",
       "      <th>jon</th>\n",
       "      <th>fakeOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this new game of thrones night king theory is ...</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>congratulations for winning awards tonight wor...</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>more breaking news jinyoung of got and his vis...</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>congratulations for winning awards tonight wor...</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>congratulations for winning awards tonight wor...</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  length  euron  sansa  \\\n",
       "0  this new game of thrones night king theory is ...      78      0      0   \n",
       "1  congratulations for winning awards tonight wor...      96      0      0   \n",
       "2  more breaking news jinyoung of got and his vis...     109      0      0   \n",
       "3  congratulations for winning awards tonight wor...      96      0      0   \n",
       "4  congratulations for winning awards tonight wor...      96      0      0   \n",
       "\n",
       "   jaime  arya  tyrion  bran  night  daenerys  cersei  jon  fakeOrNot  \n",
       "0      0     0       0     0      1         0       0    0   0.080296  \n",
       "1      0     0       0     0      1         0       0    0   0.024360  \n",
       "2      0     0       0     0      1         0       0    0   0.470850  \n",
       "3      0     0       0     0      1         0       0    0   0.024360  \n",
       "4      0     0       0     0      1         0       0    0   0.024360  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPred = pd.read_csv('./data/fakenewsprediction.csv')\n",
    "dfPred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(stri):\n",
    "    stri = re.sub(r'[^\\w\\s\\d]','',stri)\n",
    "    stri = stri.replace('/n', ' ')\n",
    "    stri = stri.replace('\\n', ' ')\n",
    "    return stri.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPred['text'] = dfPred['text'].map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[23022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector i'm here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isn't\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([idx2word[o] for o in x_train[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's limit to a vocab size of 5000 words. it is already sorted, so we will replace all the rare words with the 5000-th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "\n",
    "trn = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_train]\n",
    "test = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2493, 10, 237.71364)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "lens = np.array(list(map(len, trn)))\n",
    "(lens.max(), lens.min(), lens.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pad shorter sentences with a given word, such that in the end we will have a matrixfor which each row represents a review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 500\n",
    "\n",
    "X_train = pad_sequences(trn, maxlen=seq_len, value=0)\n",
    "X_test = pad_sequences(test, maxlen=seq_len, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(text):\n",
    "    lista = text.split(' ')\n",
    "    return [word2idx[s] if s in vocab else 0 for s in lista]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPred['indices'] = dfPred['text'].map(transform)\n",
    "X_pred = dfPred['indices'].tolist()\n",
    "X_pred = [np.array(el) for el in X_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = pad_sequences(X_pred, maxlen=seq_len, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use GloVe Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if keras has an embedding layer, to capture semantics, we will use a pretrained GloVe embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_glove(loc):\n",
    "    with open(loc+'_words.pkl', 'rb') as f1:\n",
    "            r1 = pickle.load(f1, encoding='latin1')\n",
    "    with open(loc+'_idx.pkl', 'rb') as f2:\n",
    "            r2 = pickle.load(f2, encoding='latin1')\n",
    "    return (bcolz.open(loc+'.dat')[:], r1, r2)\n",
    "\n",
    "\n",
    "vecs, words, wordidx = load_glove(r'./6B.300d/6B.300d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fact = 300\n",
    "\n",
    "def create_emb():\n",
    "    n_fact = vecs.shape[1]\n",
    "    emb = np.zeros((vocab_size, n_fact))\n",
    "\n",
    "    for i in range(1,len(emb)):\n",
    "        word = idx2word[i]\n",
    "        if word in words and re.match(r\"^[a-zA-Z\\-]*$\", word):\n",
    "            src_idx = wordidx[word]\n",
    "            emb[i] = vecs[src_idx] #vecs[wordidx[w]]\n",
    "        else:\n",
    "            # If we can't find the word in glove, randomly initialize\n",
    "            emb[i] = np.random.normal(scale=0.6, size=(n_fact,))\n",
    "\n",
    "    # This is our \"rare word\" id - we want to randomly initialize\n",
    "    emb[-1] = np.random.normal(scale=0.6, size=(n_fact,))\n",
    "    emb/=3\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model. Fit. Predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use one LSTM followed by two dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(vocab_size, n_fact, seq_len):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    vocab_size, vocabulary size\n",
    "    n_fact, no of embedding factors\n",
    "    seq_len, length of the sequence\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    input_X = Input(shape=(seq_len, ))\n",
    "    embed = Embedding(vocab_size, 300, input_length=seq_len, mask_zero=True,\n",
    "              embeddings_regularizer=l2(1e-6), weights = [emb])\n",
    "    X = embed(input_X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(32, activation='relu',kernel_regularizer=l2(0.05),\n",
    "             activity_regularizer=l2(0.01))(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dropout(0.7)(X)\n",
    "    out = Dense(1, activation='sigmoid',kernel_regularizer=l2(0.05),\n",
    "               activity_regularizer=l2(0.005))(X)\n",
    "    # Create model instance \n",
    "    model = Model(inputs=input_X, outputs=out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 500, 300)          1500000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 300)          1200      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,725,649\n",
      "Trainable params: 1,724,729\n",
      "Non-trainable params: 920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model(vocab_size, n_fact=300, seq_len=seq_len)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "2051s - loss: 0.8482 - acc: 0.4998 - val_loss: 0.7215 - val_acc: 0.5000\n",
      "Epoch 2/4\n",
      "1887s - loss: 0.7175 - acc: 0.5038 - val_loss: 0.7159 - val_acc: 0.5000\n",
      "Epoch 3/4\n",
      "1878s - loss: 0.7156 - acc: 0.4985 - val_loss: 0.7160 - val_acc: 0.5000\n",
      "Epoch 4/4\n",
      "1912s - loss: 0.7148 - acc: 0.4988 - val_loss: 0.7151 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faf4c2577b8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.01\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=4, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPred['Sentiment'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>euron</th>\n",
       "      <th>sansa</th>\n",
       "      <th>jaime</th>\n",
       "      <th>arya</th>\n",
       "      <th>tyrion</th>\n",
       "      <th>bran</th>\n",
       "      <th>night</th>\n",
       "      <th>daenerys</th>\n",
       "      <th>cersei</th>\n",
       "      <th>jon</th>\n",
       "      <th>fakeOrNot</th>\n",
       "      <th>indices</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this new game of thrones night king theory is ...</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080296</td>\n",
       "      <td>[11, 159, 497, 4, 60913, 311, 708, 2601, 6, 18...</td>\n",
       "      <td>0.466841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>congratulations for winning awards tonight wor...</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024360</td>\n",
       "      <td>[10308, 15, 1573, 2125, 4484, 179, 320, 890, 2...</td>\n",
       "      <td>0.466841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>more breaking news jinyoung of got and his vis...</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470850</td>\n",
       "      <td>[50, 2241, 1633, 0, 4, 185, 2, 24, 2054, 6, 29...</td>\n",
       "      <td>0.466841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>congratulations for winning awards tonight wor...</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024360</td>\n",
       "      <td>[10308, 15, 1573, 2125, 4484, 179, 320, 890, 2...</td>\n",
       "      <td>0.466841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>congratulations for winning awards tonight wor...</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024360</td>\n",
       "      <td>[10308, 15, 1573, 2125, 4484, 179, 320, 890, 2...</td>\n",
       "      <td>0.466841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  length  euron  sansa  \\\n",
       "0  this new game of thrones night king theory is ...      78      0      0   \n",
       "1  congratulations for winning awards tonight wor...      96      0      0   \n",
       "2  more breaking news jinyoung of got and his vis...     109      0      0   \n",
       "3  congratulations for winning awards tonight wor...      96      0      0   \n",
       "4  congratulations for winning awards tonight wor...      96      0      0   \n",
       "\n",
       "   jaime  arya  tyrion  bran  night  daenerys  cersei  jon  fakeOrNot  \\\n",
       "0      0     0       0     0      1         0       0    0   0.080296   \n",
       "1      0     0       0     0      1         0       0    0   0.024360   \n",
       "2      0     0       0     0      1         0       0    0   0.470850   \n",
       "3      0     0       0     0      1         0       0    0   0.024360   \n",
       "4      0     0       0     0      1         0       0    0   0.024360   \n",
       "\n",
       "                                             indices  Sentiment  \n",
       "0  [11, 159, 497, 4, 60913, 311, 708, 2601, 6, 18...   0.466841  \n",
       "1  [10308, 15, 1573, 2125, 4484, 179, 320, 890, 2...   0.466841  \n",
       "2  [50, 2241, 1633, 0, 4, 185, 2, 24, 2054, 6, 29...   0.466841  \n",
       "3  [10308, 15, 1573, 2125, 4484, 179, 320, 890, 2...   0.466841  \n",
       "4  [10308, 15, 1573, 2125, 4484, 179, 320, 890, 2...   0.466841  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
